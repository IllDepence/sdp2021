{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from xml.etree.ElementTree import Element, SubElement, Comment, tostring\n",
    "from xml.dom import minidom\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify(elem):\n",
    "    \"\"\"Return a pretty-printed XML string for the Element.\n",
    "    \"\"\"\n",
    "    rough_string = tostring(elem, 'utf-8')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    return reparsed.toprettyxml(indent=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function that removes \"arrays\" from the author fields\n",
    "\n",
    "def removeAutor(my_str):\n",
    "    my_str1 = re.sub(\"\\['\", \"\", my_str)\n",
    "    my_str2 = re.sub(\"'\\]\", \"\", my_str1)\n",
    "    my_str3 = re.sub(\"'\", \"\", my_str2)\n",
    "    return(my_str3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function that removes new lines\n",
    "def removePassage(my_str):\n",
    "    my_str1 = re.sub(\"\\\\\\\\ud\", \" \", my_str)\n",
    "    my_str2 = re.sub(\"\\\\\\\\n\", \" \", my_str1)\n",
    "    return(my_str2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Core Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(\"metadata_15553.csv\") # path to metadata (coreID,titles,authors) of final selection of papers\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to GROBID \"createTraining\" batch command created TEIs [\"Core_ID_xxxxxxx.training.header.tei.xml\"]\n",
    "path_input = \"/header_training\"\n",
    "path_output = \"/header_training_edited\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file paths and CORE Ids from the GROBID \"createTraining\" batch command created TEIs\n",
    "files = []\n",
    "file_paths = []\n",
    "core_ids= []\n",
    "for r, d, f in os.walk(path_input+\"/TEI\"):\n",
    "    for file in f:\n",
    "        files.append(file)\n",
    "        file_paths.append(os.path.join(r, file))\n",
    "        ID = file.replace('Core_ID_',\"\").replace(\".training.header.tei.xml\",'')\n",
    "        core_ids.append(ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Training TEI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Function for labelling of the data\n",
    "\n",
    "no_autor = []\n",
    "no_title = []\n",
    "error_papers = []\n",
    "result_tokens = []\n",
    "result_label = []\n",
    "i = 0\n",
    "\n",
    "for core_id, file_path in zip(core_ids,file_paths):\n",
    "\n",
    "    try:\n",
    "        del end_title\n",
    "        del beg_title\n",
    "        del end_author\n",
    "        del beg_author\n",
    "    except:\n",
    "        pass\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    prettify(root)\n",
    "    \n",
    "    tei_string = ET.tostring(root, encoding='utf8').decode('utf8').replace('-<lb />','- ').replace('<lb />-',' -').replace('<lb />','')\n",
    "    text_tei = re.sub('(<.*?>)|(\\\\n)|(\\\\t)',' ',tei_string)\n",
    "    text_tei = ' '.join(text_tei.split())\n",
    "\n",
    "    \n",
    "    # Remove the \"front\" node\n",
    "    for elem in root.iter():\n",
    "        for child in list(elem):\n",
    "            if child.tag == 'front':\n",
    "                elem.remove(child)\n",
    "\n",
    "                \n",
    "    paper_meta = df_meta.loc[df_meta.coreId == int(core_id)]\n",
    "    \n",
    "    title = ' '.join(removePassage(paper_meta.title.iloc[0]).split()).lower()\n",
    "    \n",
    "    authors = removeAutor(paper_meta.authors.iloc[0]).split(\",\")\n",
    "    autors = []\n",
    "    for j in range(len(authors)):\n",
    "\n",
    "        autor_pdf = ' '.join(authors[j].split()) ## Remove excessive Whitespaces\n",
    "        autors.append(autor_pdf)\n",
    "    \n",
    "    if text_tei.lower().find(title) < 0:\n",
    "        no_title.append(core_id)\n",
    "    else:\n",
    "        beg_title = text_tei.lower().find(title)\n",
    "        end_title = beg_title + len(title)\n",
    "        range_title = list(range(beg_title,end_title))\n",
    "    try:\n",
    "\n",
    "        autors_surname = []\n",
    "        for i in range(len(autors)):\n",
    "            if i % 2 == 0:\n",
    "                autors_surname.append(autors[i])\n",
    "\n",
    "        autors_surname_lower = []\n",
    "        for i in range(len(autors_surname)):\n",
    "            autors_surname_lower.append(autors_surname[i].lower())\n",
    "\n",
    "        if re.match('.\\.',autors[1]) == None:\n",
    "            autors_forename = []\n",
    "            for i in range(len(autors)):\n",
    "                if i % 2 == 1:\n",
    "                    autors_forename.append(autors[i].split())\n",
    "\n",
    "            autors_forename = list(np.concatenate((autors_forename), axis=None))\n",
    "            autors_forename_lower = []\n",
    "            for i in range(len(autors_forename)):\n",
    "                autors_forename_lower.append(autors_forename[i].lower())\n",
    "\n",
    "            autors_surname_lower = list(np.concatenate((autors_forename_lower,autors_surname_lower), axis=None))\n",
    "\n",
    "        beg_author = []\n",
    "        end_author = []\n",
    "        for autor in autors_surname_lower:\n",
    "            beg = text_tei.lower().find(autor)\n",
    "            if beg>-1:\n",
    "                if beg not in beg_author:\n",
    "                    beg_author.append(text_tei.lower().find(autor))\n",
    "                    end_author.append(text_tei.lower().find(autor) + len(autor))\n",
    "                else:\n",
    "                    while text_tei.lower().find(autor,beg+1)>-1:\n",
    "                        if text_tei.lower().find(autor,beg+1) in beg_author:\n",
    "                            beg = 999999999\n",
    "                            \n",
    "                        else:\n",
    "                            beg_author.append(text_tei.lower().find(autor,beg+1))\n",
    "                            end_author.append(text_tei.lower().find(autor,beg+1) + len(autor))\n",
    "                            beg = text_tei.lower().find(autor,beg+1)\n",
    "\n",
    "\n",
    "        if beg_author==[]:\n",
    "            no_autor.append(core_id)    \n",
    "\n",
    "        if len(beg_author)>len(autors_surname_lower):\n",
    "            span_author = dict(zip(beg_author,end_author))\n",
    "            diff = len(beg_author) - len(autors_surname_lower)\n",
    "            dist = []\n",
    "            for p in beg_author:\n",
    "                if p<beg_title:\n",
    "                    dist.append(abs(p - beg_title))\n",
    "                else:\n",
    "                    dist.append(abs(p - end_title))\n",
    "\n",
    "            dict1 = dict(zip(dist , beg_author))      \n",
    "            dist.sort(reverse = False)\n",
    "\n",
    "            for k in range(len(dist[0:diff])):\n",
    "                b =[]\n",
    "                e = []\n",
    "                b.append(dict1[dist[k]])\n",
    "                e.append(span_author[dict1[dist[k]]])\n",
    "                beg_author = b\n",
    "                end_author = e     \n",
    "        \n",
    "        if re.search('.\\.',autors[1]) != None:\n",
    "            for ba,ea in zip(beg_author,end_author):\n",
    "                if re.search('(.\\..\\.)|(.\\. .\\.)|(.\\.. \\.)|(. \\. . \\.)',text_tei[ba-7:ba]) != None and any(token.isupper() for token in text_tei[ba-7:ba].split()):\n",
    "                    span = re.search('(.\\..\\.)|(.\\. .\\.)|(.\\.. \\.)|(. \\. . \\.)',text_tei[ba-7:ba]).span()\n",
    "                    beg_author.append(ba-7+span[0])\n",
    "                    end_author.append(ba-7+span[1])\n",
    "                if re.search('(.\\..\\.)|(.\\. .\\.)|(.\\.. \\.)|(. \\. . \\.)',text_tei[ea:ea+7]) != None and any(token.isupper() for token in text_tei[ea:ea+7].split()):\n",
    "                    span = re.search('(.\\..\\.)|(.\\. .\\.)|(.\\.. \\.)|(. \\. . \\.)',text_tei[ea:ea+7]).span()\n",
    "                    beg_author.append(ea + span[0])\n",
    "                    end_author.append(ea + span[1])\n",
    "         \n",
    "        beg_author = list(dict.fromkeys(beg_author))\n",
    "        end_author = list(dict.fromkeys(end_author))\n",
    "        beg_author.sort(reverse=False)\n",
    "        end_author.sort(reverse=False)\n",
    "        \n",
    "        indices_author = []\n",
    "        dist_author= []\n",
    "        for ba,ea in zip(beg_author[1:],end_author[:len(end_author)-1]):\n",
    "            dist_author.append(abs(ba-ea))\n",
    "        if all(dist<6 for dist in dist_author):\n",
    "            indices_author = [min(beg_author),max(end_author)]\n",
    "        else:\n",
    "            indices_author= list(np.concatenate((beg_author,end_author)))\n",
    "            for ba,ea in zip(beg_author[1:],end_author[:len(end_author)-1]):\n",
    "                if abs(ba-ea)<6:\n",
    "                    indices_author.remove(ba)\n",
    "                    indices_author.remove(ea)\n",
    "        \n",
    "        beg_author2 = []\n",
    "        end_author2 = []\n",
    "        for i in range(len(indices_author)):\n",
    "            if i%2==0:\n",
    "                beg_author2.append(indices_author[i])\n",
    "            else: \n",
    "                end_author2.append(indices_author[i])\n",
    "        range_authors=[]\n",
    "        for i in range(len(beg_author2)):\n",
    "            range_list = list(range(beg_author2[i],end_author2[i]))\n",
    "            range_authors = list(np.concatenate((range_authors,range_list)))\n",
    "            \n",
    "        indices = indices_author\n",
    "        indices.append(beg_title)\n",
    "        indices.append(end_title)\n",
    "        indices.sort(reverse = False)\n",
    "        parts = [text_tei[i:j] for i,j in zip(indices, indices[1:]+[None])]\n",
    "        \n",
    "        text = root[1]\n",
    "        front = SubElement(text , 'front')\n",
    "\n",
    "        final_string = ''\n",
    "        if min(indices)!=0:\n",
    "            final_string+=text_tei[0:min(indices)]\n",
    "\n",
    "        for i in range(len(parts)):\n",
    "#             print(parts[i])\n",
    "            if parts[i].lower()== title.lower():\n",
    "                final_string+='<docTitle><titlePart>'+ parts[i] +'</titlePart></docTitle>'\n",
    "            elif indices[i] in range_authors: \n",
    "                final_string+=\"<byline><docAuthor> \"+ parts[i] + \"</docAuthor></byline>\" \n",
    "            else:\n",
    "                final_string+=parts[i]\n",
    "        front.text = final_string\n",
    "        file_name = path_output + \"/TEI/Core_ID_\" + str(core_id) +\".training.header.tei.xml\"\n",
    "        mydata = str(prettify(root)).replace(\"&lt;\",\"<\").replace(\"&gt;\",\">\")\n",
    "        myfile = open(file_name, \"w\",encoding=\"utf-8\")\n",
    "        myfile.write(mydata)\n",
    "        myfile.close()\n",
    "        \n",
    "        shutil.copyfile(path_input+\"/HEADER/Core_ID_\" + str(core_id) + \".training.header\",\n",
    "                        path_output+ \"/HEADER/Core_ID_\" + str(core_id) + \".training.header\")\n",
    "    except:\n",
    "        i=i+1\n",
    "        print(\"SEVERE ERROR \"+ str(core_id)+ \"\\n\"+str(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
